---
sidebar_position: 10
title: Development flow
description: Development flow for building squids
---

# Development flow

Below is a general outline of the squid development steps. 

### 0. Prerequisites

- Get familiar with squids and Archives by reading the [Overview](/basics/overview)
- Follow through the [Quickstart](/quickstart) and scaffold a new squid project using [sqd init](/squid-cli/init) and a suitable template.

### 1. Model the data with a schema file

Start the development by defining the data schema in `schema.graphql` in the squid root folder. The schema will be used both for the target database and for the GraphQL API. It consists of regular GraphQL type declarations annotated with custom directives to define:
- relations between the entities
- entity properties, property types and entity relations 
- indexes to be created in the database
- the schema of the auto-generated GraphQL API

A full reference of the `schema.graphql` dialect is available in the [schema file section](/basics/schema-file).

### 2. Generate TypeORM classes

The squid processor data handlers use [TypeORM](https://typeorm.io) entities
to interact with the target database during the data processing. All necessary entity classes are
generated by the squid framework from `schema.graphql` with 
```bash
sqd codegen
```

By convention, the generated model classes are kept in `src/model/generated`. Custom user-defined entities can
be added in `src/model/index.ts`.

### 3. Generate the database migrations

For this step you need a clean Postgres database running locally:
```bash
# drop the old schema
sqd down
# start a clean Postgres in Docker
sqd up
```

Database schema changes (including initialization) are applied through migration files located at `db/migrations`. Generate migrations as follows:
```bash
# remove the old migrations
sqd migration:clean
# compile the squid code, notably the TypeORM model classes
sqd build
# generate the new schema migrations at db/migrations
sqd migration:generate
```

Consult [database migrations](/basics/db-migrations) for more details.

### 4. Define the squid processor and the data handlers

A squid processor is a node.js process that fetches historical on-chain data, performs arbitrary transformations and saves the result into the target database schema defined above. By convention, the processor entry point is `src/processor.ts`.

- [`EvmBatchProcessor`](/evm-indexing) (imported from `@subsquid/evm-processor`) is used for EVM chains
- [`SubstrateBatchProcessor`](/substrate-indexing) (imported from `@subsquid/substrate-processor`) is used for Substrate-based chains



### 5. Initialize a suitable processor instance 

Configure the processor by defining:
- the archive endpoint
- indexing data range
- data to be extracted from the Archive

**Example:**
```ts
const processor = new EvmBatchProcessor()
  .setDataSource({
    archive: 'https://eth.archive.subsquid.io',
  })
  .addTransaction([
    '0x0000000000000000000000000000000000000000'
  ], {
    range: {
      from: 6_000_000
    },
    data: {
      transaction: {
        from: true,
        input: true,
        to: true
      }
    }
  });
```

See [EvmBatchProcessor configuration](/evm-indexing/configuration) and [SubstrateBatchProcessor configuration](/substrate-indexing/configuration) for details.

### 6. Generate Typescript facade classes to decode the obtained on-chain data

- For EVM data, use [`evm-typegen`](/evm-indexing/squid-evm-typegen)
- For Substrate data, use [`substrate-typegen`](/substrate-indexing/squid-substrate-typegen)
- For ink! smart contract data, use [`ink-typegen`](https://github.com/subsquid/squid-sdk/tree/master/substrate/ink-typegen)

### 7. Define the processor batch handler for the `processor.run()` call

Squid SDK embraces the [batch-based programming model](/basics/batch-processing). Within a running processor, the `.run()` method repeatedly applies a user-supplied batch handler function to the batches of data retrieved from an Archive. The method takes two arguments: a [store adaptor](/basics/store) for connecting to the database of choice and an `async` batch handler function. The only argument of the batch handler is a [context object](/basics/processor-context) that contains the batch data, some useful metadata and a store adapter reference. Its interface slightly varies depending on the processor flavor:

- For `EvmBatchProcessor`, see [`BatchContext` for EVM](/evm-indexing/context-interfaces)
- For `SubstrateBatchProcessor`, see the [`BatchContext` for Substrate](/substrate-indexing/context-interfaces)

**Example:**
```ts
processor.run(new TypeormDatabase(), async (ctx) => {
  const entities: Map<string, FooEntity> = new Map();
  // process a batch of data 
  for (const c of ctx.blocks) {
    // the data is packed into blocks, 
    // each block contains only the requested items
    for (const irem of c.items) {
      if(e.kind === 'evmLog') {
        // decode, extract and transform the evm log data
        const { baz, bar, id } = extractLogData(e.evmLog)
        entities.set(id, new FooEntity({
          id,
          baz,
          bar
        })) 
      }
      if (e.kind === 'transaction') {
        // decode tx data if requested
      }
    }
  }
  // upsert data to the target db in single batch
  await ctx.store.save([...entities.values()])
});
```

For an end-to-end walkthrough, see

- [`EvmBatchProcessor` in action](/evm-indexing/batch-processor-in-action)
- [`SubstrateBatchProcessor` in action](/substrate-indexing/batch-processor-in-action)


### 8. Run the squid services

Run the processor with
```bash
sqd process
```

Run the GraphQL server in a separate terminal window with
```bash
sqd serve
```
The GraphQL playground will be available at [`http://localhost:4350/graphql`](http://localhost:4350/graphql).

### 9. Deploy the squid

Follow the [Deploy Squid](/deploy-squid) section.

## What's next?

- Learn from the [Squids examples](/examples)
- Get familiar with the typegen tools for [EVM](/evm-indexing/squid-evm-typegen) or [Substrate](/substrate-indexing/squid-substrate-typegen)
