---
sidebar_position: 20
title: Development flow
description: Development flow for building squids
---

# Development flow

Below is a general outline of the squid development steps. 

### 0. Prerequisites

- Get familiar with squids and Archives by reading the [Overview](/basics/overview)
- Follow through the [Quickstart](/quickstart) and scaffold a new squid project using [sqd init](/squid-cli/init) and a suitable template.

### 1. Model the data with a schema file

Start the development by defining the data schema in `schema.graphql` in the squid root folder. The schema will be used both for the target database and for the GraphQL API. It consists of regular GraphQL type declarations annotated with custom directives to define:
- relations between the entities
- entity properties, property types and entity relations 
- indexes to be created in the database
- the schema of the auto-generated GraphQL API

A full reference of the `schema.graphql` dialect is available in the [schema file section](/basics/schema-file).

### 2. Generate TypeORM classes

The squid processor data handlers use [TypeORM](https://typeorm.io) entities
to interact with the target database during the data processing. All necessary entity classes are
generated by the squid framework from `schema.graphql` with 
```bash
sqd codegen
```

By convention, the generated model classes are kept in `src/model/generated`. Custom user-defined entities can
be added in `src/model/index.ts`.

### 3. Generate the database migrations

For this step you need a clean Postgres database running locally:
```bash
# drop the old schema
sqd down
# start a clean Postgres in Docker
sqd up
```

Database schema changes (including initialization) are applied through migration files located at `db/migrations`. Generate migrations as follows:
```bash
# compiles the code, removes the old migrations and replaces them with new ones
sqd migration:generate
```

Consult [database migrations](/basics/db-migrations) for more details.

### 4. Define the squid processor and the data handlers

A squid processor is a node.js process that fetches historical on-chain data, performs arbitrary transformations and saves the result into the target database schema defined above. By convention, the processor entry point is `src/main.ts` and the main processor object is defined at `src/processor.ts`.

- [`EvmBatchProcessor`](/evm-indexing) (imported from `@subsquid/evm-processor`) is used for EVM chains
- [`SubstrateBatchProcessor`](/firesquid/substrate-indexing) (imported from `@subsquid/substrate-processor`) is used for Substrate-based chains

[//]: # (!!!! Remove the /firesquid reference above once ArrowSquid for Substrate is released)

### 5. Initialize a suitable processor instance 

Configure the processor by defining:
- the archive endpoint
- indexing data range
- data to be extracted from the Archive

**Example:**
```ts title=src/processor.ts
export const processor = new EvmBatchProcessor()
  .setDataSource({
    archive: lookupArchive('eth-mainnet'),
    chain: 'https://eth-rpc.gateway.pokt.network'
  })
  .setFinalityConfirmation(75)
  .addTransaction({
    address: ['0x0000000000000000000000000000000000000000'],
    range: {from: 6_000_000}
  })
  .setFields({
    transaction: {
      from: true,
      input: true,
      to: true
    }
  })
```

See [EvmBatchProcessor configuration](/evm-indexing/configuration) and [SubstrateBatchProcessor configuration](/firesquid/substrate-indexing/configuration) for details.

[//]: # (!!!! Update the link above once ArrowSquid for Substrate is released)

### 6. Generate Typescript facade classes to decode the obtained on-chain data

- For EVM data, use [`evm-typegen`](/evm-indexing/squid-evm-typegen)
- For Substrate data, use [`substrate-typegen`](/firesquid/substrate-indexing/squid-substrate-typegen)
- For ink! smart contract data, use [`ink-typegen`](https://github.com/subsquid/squid-sdk/tree/master/substrate/ink-typegen)

### 7. Define the processor batch handler for the `processor.run()` call

Squid SDK embraces the [batch-based programming model](/basics/batch-processing). Within a running processor, the `.run()` method repeatedly applies a user-supplied batch handler function to the batches of data retrieved from an Archive. The method takes two arguments: a [store adaptor](/basics/store) for connecting to the database of choice and an `async` batch handler function. The only argument of the batch handler is a [context object](/basics/squid-processor/#batch-context) that contains the batch data, some useful metadata and a store adapter reference. Its interface slightly varies depending on the processor flavor:

- For `EvmBatchProcessor`, see [`DataHandlerContext` for EVM](/evm-indexing/context-interfaces)
- For `SubstrateBatchProcessor`, see the [`BatchContext` for Substrate](/firesquid/substrate-indexing/context-interfaces)

[//]: # (!!!! Update the link above once ArrowSquid for Substrate is released)

**Example:**
```ts title=src/main.ts
processor.run(new TypeormDatabase(), async (ctx) => {
  const entities: Map<string, FooEntity> = new Map()
  // process a batch of data 
  for (let block of ctx.blocks) {
    // The data is packed into blocks.
    // Each block contains the requested items.
    // It may also contain some items that were not requested,
    // so the data must be filtered in the batch handler.
    for (let log of block.logs) {
      if (log.address === CONTRACT_ADDRESS && log.topic0 === fooEventTopic) {
        // decode, extract and transform the evm log data
        const { baz, bar, id } = extractLogData(log)
        entities.set(id, new FooEntity({
          id,
          baz,
          bar
        }))
      }
    }
    for (let txn of block.transactions) {
      // filter and decode txn data if requested
    }
  }
  // upsert data to the target db in single batch
  await ctx.store.save([...entities.values()])
})
```

For an end-to-end walkthrough, see

- [`EvmBatchProcessor` in action](/evm-indexing/batch-processor-in-action)
- [`SubstrateBatchProcessor` in action](/firesquid/substrate-indexing/batch-processor-in-action)

[//]: # (!!!! Remove the /firesquid reference above once ArrowSquid for Substrate is released)

### 8. Run the squid services

Run the processor with
```bash
sqd process
```

Run the GraphQL server in a separate terminal window with
```bash
sqd serve
```
The GraphQL playground will be available at [`http://localhost:4350/graphql`](http://localhost:4350/graphql).

### 9. Deploy the squid

Follow the [Deploy Squid](/deploy-squid) section.

## What's next?

- Learn from the [Squids examples](/examples)
- Get familiar with the typegen tools for [EVM](/evm-indexing/squid-evm-typegen) or [Substrate](/firesquid/substrate-indexing/squid-substrate-typegen)

[//]: # (!!!! Update the /firesquid links above once ArrowSquid for Substrate is released)
